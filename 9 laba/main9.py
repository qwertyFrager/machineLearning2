import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from apyori import apriori

data = pd.read_csv('DataSet9_2.csv', sep = ',', on_bad_lines='skip')

data.head()


# Обучение ассоциативным правилам
# Обучение ассоциативным правилам - одна из важнейших концепций машинного обучения. Применяется в анализе рыночной
# корзины и статистики посещения сайтов, непрерывном производстве и т. д. Анализ рыночной корзины - это метод,
# используемый в крупных розничных сетях для выявления ассоциативных связей между товарами. Для его понимания
# показателен пример супермаркета, где все покупаемые вместе продукты раскладываются на полках рядом.

# Введение в APRIORI
# В основе Apriori - поиск частотных множеств элементов в наборе данных. Этот алгоритм построен на ассоциациях и
# корреляциях между наборами элементов. Он применяется на рекомендательных платформах - там, где мы обычно видим
# «вам также может понравиться».
# В алгоритме Apriori предполагается, что любое подмножество частотного набора элементов должно быть частотным.
# Например, если транзакция {молоко, яйца, хлеб} частотна, должна быть частотной и ее составляющая {яйца, хлеб}.

# Принцип работы Apriori
# Чтобы из всего многообразия правил отобрать интересные, для примера супермаркета применим следующие показатели:

# Support (поддержка) - в общем виде это показатель «частотности»;
# Определяет, как часто набор элементов встречается в транзакциях.
# Формула:
# Support = Количество транзакций с набором X / Общее кол-во транзакций

# Lift (лифт) - это отношение «зависимости» items к их «независимости». Lift показывает, насколько items зависят друг
# от друга;
# Показывает, насколько зависимость между товарами A и B выше, чем ожидалось при их независимости.

# Confidence (уверенность) - как часто наше правило срабатывает для всего датасета.
# Показывает, с какой вероятностью товар B покупается вместе с товаром A, если A уже куплен.



#Библиотека APYORI требует использование списка списков.

data = data.astype(str)
data['Make + Model'] = data['Make'] + ' ' + data['Model']
data['City + State'] = data['City'] + ' ' + data['State']
data.drop(['Make', 'Model', 'Vin', 'City', 'State', 'Id'], axis=1, inplace = True)
transactions = data.values.tolist()
data.head()


rules = apriori(transactions = transactions, min_support = 0.001, min_cinfidence = 0.001, min_lift = 1.1, min_length = 2, max_length = 2)
results = list(rules)

def inspect(results):
    lhs = [tuple(result[2][0][0])[0] for result in results]
    rhs = [tuple(result[2][0][1])[0] for result in results]
    supports = [result[1] for result in results]
    confidences = [result[2][0][2] for result in results]
    lifts = [result[2][0][3] for result in results]
    return list (zip(lhs, rhs, supports, confidences, lifts))
resultsinDataFrame = pd.DataFrame(inspect(results), columns = ["Left hand side", "Right hand side", "Support", "Confidence", "Lift"])

resultsinDataFrame = resultsinDataFrame.nlargest(n = 10, columns = "Lift")

data_10_best = resultsinDataFrame[:10]

import plotly.express as px
fig = px.scatter(data_10_best, x='Support', y='Confidence', color='Lift')
fig.show()

import plotly.express as px
fig = px.scatter(data_10_best, x='Left hand side', y='Right hand side', color='Lift', size = 'Support')
fig.show()


# График визуализирует ассоциативные правила, полученные с помощью алгоритма Apriori. Трактовка данных на графике:
#
# Оси:
# Left hand side (горизонтальная ось): Левые элементы ассоциативных правил (товары или категории, с которыми связаны правила).
# Right hand side (вертикальная ось): Правые элементы ассоциативных правил (товары или категории, которые связаны с левой частью).

# Цвет точек:
# Цвет точек обозначает Lift (лифт) — насколько сильна взаимосвязь между товарами по сравнению с их независимой встречаемостью. Чем выше лифт (ярче цвет), тем значимее правило.

# Размер точек:
# Размер точек отображает Support (поддержку) — насколько часто данная пара встречается в транзакциях. Чем больше точка, тем чаще встречается данная связь.

# Пример интерпретации:

# Chevrolet Malibu -> Kia SedonaLX:
# Левый товар — "Chevrolet Malibu", правый — "Kia SedonaLX".
# Лифт высокий, поэтому при покупке "Chevrolet Malibu" значительно возрастает вероятность покупки "Kia SedonaLX".
# Размер точки указывает, что эта комбинация встречается не так часто (низкая поддержка).

# Hyundai Sonata4dr -> Mercedes-Benz C-ClassC:
# Высокий лифт показывает значимую взаимосвязь между этими товарами.
# Поддержка также выше (больше точка), что указывает на регулярную встречаемость этой пары.

# Выводы:

# График помогает выделить товары с высокой корреляцией. Их можно использовать для:

# Создания акций или рекомендательных систем.
# Выкладки товаров рядом друг с другом в магазине.
# Планирования маркетинговых стратегий.